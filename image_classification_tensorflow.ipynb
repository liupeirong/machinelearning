{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = '/path/to/processed_images'\n",
    "\n",
    "imgs, labels = utils.load(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a few sample images to ensure everything is read correctly\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(imgs[i*113])\n",
    "    plt.title(\"labl {}\".format(labels[i*113]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert one-hot-encoded value back to string label, and index of predicted class back to string label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels, ids = np.unique(labels, return_inverse=True)\n",
    "\n",
    "def index_to_category(index):\n",
    "    return unique_labels[index]\n",
    "\n",
    "def ohe_label_to_category(ohe_label):\n",
    "    return index_to_category(ohe_label.argmax(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "#['a', 'b', 'a', 'c', 'b'] \n",
    "#=>\n",
    "#[[1,0,0], [0,1,0], [1,0,0], [0,0,1], [0,1,0]]\n",
    "\n",
    "mylbs = ['a', 'b', 'a', 'c', 'b', 'd'] \n",
    "print(type(mylbs))\n",
    "myuniques, myids = np.unique(mylbs, return_inverse=True)\n",
    "print(myuniques)\n",
    "print(myids)\n",
    "mylbs_ohe = np_utils.to_categorical(myids, len(myuniques))\n",
    "print(mylbs_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1,0,0] => 'a'\n",
    "myohe = array([1,0,0])\n",
    "myidx = myohe.argmax(0)\n",
    "print(myidx)\n",
    "mylb = myuniques[myidx]\n",
    "print(mylb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(imgs))\n",
    "#print(type(imgs[0]))\n",
    "#print(imgs[0].shape)\n",
    "print(len(imgs[0].flatten()))\n",
    "#print(type(array(imgs)))\n",
    "#print(array(imgs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels_ohe = utils.one_hot_encode_object_array(labels)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(imgs, labels_ohe, random_state = 42)\n",
    "# tuple to numpy array\n",
    "img_train, img_test, label_train, label_test = array(x_train), array(x_test), array(y_train), array(y_test)\n",
    "\n",
    "print(\"Training matrix shape\", img_train.shape)\n",
    "print(\"Testing matrix shape\", img_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print a few training image to make sure everything is correct\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(Image.fromarray(img_train[i*87].astype('uint8'),'RGB'))\n",
    "    plt.title(\"labl {}\".format(ohe_label_to_category(label_train[i*87])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a few test image to make sure everything is correct\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(Image.fromarray(img_test[i*35].astype('uint8'),'RGB'))\n",
    "    plt.title(\"labl {}\".format(ohe_label_to_category(label_test[i*35])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize 0-255 to 0-1, it might help training\n",
    "img_train = img_train.astype('float32')\n",
    "img_train /= 255\n",
    "img_test = img_test.astype('float32')\n",
    "img_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.reset_states()\n",
    "model.add(Conv2D(filters=32, kernel_size=5, input_shape=(128,128,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "    print(model.layers[i].input)\n",
    "    print(model.layers[i].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(img_train, label_train, batch_size=12, epochs=10, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(img_test, label_test, verbose=0)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is in 0-9 classes, the index of unique labels\n",
    "predicted_classes = model.predict_classes(img_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert one-hot-encoded test label to indices\n",
    "idx_from_ohe = lambda t: t.argmax(0)\n",
    "idx_label_test = np.array([idx_from_ohe(ti) for ti in label_test])\n",
    "\n",
    "# Check which items we got right / wrong\n",
    "correct_indices = np.nonzero(predicted_classes == idx_label_test)[0]\n",
    "incorrect_indices = np.nonzero(predicted_classes != idx_label_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_test *= 255\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,12)\n",
    "plt.figure()\n",
    "for i, correct in enumerate(correct_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(Image.fromarray(img_test[correct].astype('uint8'),'RGB'))\n",
    "    plt.title(\"L:{}/P:{}\".format(index_to_category(idx_label_test[correct]), index_to_category(predicted_classes[correct])))\n",
    "\n",
    "plt.figure()\n",
    "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(Image.fromarray(img_test[incorrect].astype('uint8'),'RGB'))\n",
    "    plt.title(\"L:{}/P:{}\".format(index_to_category(idx_label_test[incorrect]), index_to_category(predicted_classes[incorrect])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "localModelPath = '/path/to/saved_model'\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(localModelPath + '/kerasModel.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(localModelPath + '/kerasModel.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
