{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a web service for inference using the Tensorflow model without Azure ML\n",
    "With Azure Machine Learning Service, you don't have to do this any more. But it does tell you how Azure ML deploys a web service from a ML model for you. Also refer to [this article](https://liupeirong.github.io/amlDockerImage/) about what's inside the Docker image built by Azure ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile kerasWebApp/keras_score.py\n",
    "\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from keras.models import model_from_json\n",
    "import utils\n",
    "\n",
    "def init():\n",
    "    global model, unique_labels, target_imagesize\n",
    "    json_file = open('kerasModel.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights('kerasModel.h5')\n",
    "    target_imagesize = 128\n",
    "    unique_labels = (['axes', 'boots', 'carabiners', 'crampons', 'gloves', 'harnesses', 'helmets', 'pulleys', 'rope', 'tents'])\n",
    "\n",
    "def index_to_category(index):\n",
    "    return unique_labels[index]\n",
    "\n",
    "def run(url):\n",
    "    response = requests.get(url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img_arr = utils.processImg(img, target_imagesize)\n",
    "    predictions = model.predict_classes(array([img_arr]))\n",
    "    \n",
    "    return index_to_category(predictions[0])\n",
    "\n",
    "def main():\n",
    "    # Test the init and run functions using test data\n",
    "    test_url = \"/url/to/image\"\n",
    "    init()\n",
    "    category = run(test_url)\n",
    "    print(category)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module for Flask web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile kerasWebApp/app.py\n",
    "from flask import Flask, request\n",
    "import json\n",
    "import keras\n",
    "from keras_score import *\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/score', methods = ['POST'])\n",
    "def scoreKeras():\n",
    "    \"\"\" Endpoint for scoring\n",
    "    \"\"\"\n",
    "    if request.headers['Content-Type'] != 'application/json':\n",
    "        return Response(json.dumps({}), status= 415, mimetype ='application/json')\n",
    "    input = request.json['url']\n",
    "    response = run(input)\n",
    "    dict = {}\n",
    "    dict['result'] = response\n",
    "    return json.dumps(dict)\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def healthy():\n",
    "    return \"Healthy\"\n",
    "\n",
    "\n",
    "# Keras Version\n",
    "@app.route('/version', methods = ['GET'])\n",
    "def version_request():\n",
    "    return keras.__version__\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0') # Ignore, Development server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile kerasWebApp/wsgi.py\n",
    "import sys\n",
    "sys.path.append('/code/') # FIXME: This is horrible\n",
    "from app import app as application\n",
    "from keras_score import *\n",
    "\n",
    "def create():\n",
    "    print(\"Initialising\")\n",
    "    init()\n",
    "    application.run(host='127.0.0.1', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile kerasWebApp/requirements.txt\n",
    "pillow\n",
    "Flask==0.11.1\n",
    "requests==2.12.3\n",
    "gunicorn==19.6.0\n",
    "json-logging-py==0.2\n",
    "keras==2.1.4\n",
    "h5py\n",
    "scikit-learn\n",
    "tensorflow==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile kerasWebApp/nginx/app\n",
    "server {\n",
    "    listen 88;\n",
    "    server_name _;\n",
    " \n",
    "    location / {\n",
    "    include proxy_params;\n",
    "    proxy_pass http://127.0.0.1:5000;\n",
    "    proxy_connect_timeout 5000s;\n",
    "    proxy_read_timeout 5000s;\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile kerasWebApp/gunicorn_logging.conf\n",
    "\n",
    "[loggers]\n",
    "keys=root, gunicorn.error\n",
    "\n",
    "[handlers]\n",
    "keys=console\n",
    "\n",
    "[formatters]\n",
    "keys=json\n",
    "\n",
    "[logger_root]\n",
    "level=INFO\n",
    "handlers=console\n",
    "\n",
    "[logger_gunicorn.error]\n",
    "level=ERROR\n",
    "handlers=console\n",
    "propagate=0\n",
    "qualname=gunicorn.error\n",
    "\n",
    "[handler_console]\n",
    "class=StreamHandler\n",
    "formatter=json\n",
    "args=(sys.stdout, )\n",
    "\n",
    "[formatter_json]\n",
    "class=jsonlogging.JSONFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile kerasWebApp/kill_supervisor.py\n",
    "import sys\n",
    "import os\n",
    "import signal\n",
    "\n",
    "\n",
    "def write_stdout(s):\n",
    "    sys.stdout.write(s)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# this function is modified from the code and knowledge found here: http://supervisord.org/events.html#example-event-listener-implementation\n",
    "def main():\n",
    "    while 1:\n",
    "        write_stdout('READY\\n')\n",
    "        # wait for the event on stdin that supervisord will send\n",
    "        line = sys.stdin.readline()\n",
    "        write_stdout('Killing supervisor with this event: ' + line);\n",
    "        try:\n",
    "            # supervisord writes its pid to its file from which we read it here, see supervisord.conf\n",
    "            pidfile = open('/tmp/supervisord.pid','r')\n",
    "            pid = int(pidfile.readline());\n",
    "            os.kill(pid, signal.SIGQUIT)\n",
    "        except Exception as e:\n",
    "            write_stdout('Could not kill supervisor: ' + e.strerror + '\\n')\n",
    "            write_stdout('RESULT 2\\nOK')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile kerasWebApp/etc/supervisord.conf \n",
    "[supervisord]\n",
    "logfile=/tmp/supervisord.log ; (main log file;default $CWD/supervisord.log)\n",
    "logfile_maxbytes=50MB        ; (max main logfile bytes b4 rotation;default 50MB)\n",
    "logfile_backups=10           ; (num of main logfile rotation backups;default 10)\n",
    "loglevel=info                ; (log level;default info; others: debug,warn,trace)\n",
    "pidfile=/tmp/supervisord.pid ; (supervisord pidfile;default supervisord.pid)\n",
    "nodaemon=true               ; (start in foreground if true;default false)\n",
    "minfds=1024                  ; (min. avail startup file descriptors;default 1024)\n",
    "minprocs=200                 ; (min. avail process descriptors;default 200)\n",
    "\n",
    "[program:gunicorn]\n",
    "command=bash -c \"gunicorn --workers 1 -m 007 --timeout 100000 --capture-output --error-logfile - --log-level debug --log-config gunicorn_logging.conf \\\"wsgi:create()\\\"\"\n",
    "directory=/code\n",
    "redirect_stderr=true\n",
    "stdout_logfile =/dev/stdout\n",
    "stdout_logfile_maxbytes=0\n",
    "startretries=2\n",
    "startsecs=20\n",
    "\n",
    "[program:nginx]\n",
    "command=/usr/sbin/nginx -g \"daemon off;\"\n",
    "startretries=2\n",
    "startsecs=5\n",
    "priority=3\n",
    "\n",
    "[eventlistener:program_exit]\n",
    "command=python kill_supervisor.py\n",
    "directory=/code\n",
    "events=PROCESS_STATE_FATAL\n",
    "priority=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile kerasWebApp/dockerfile\n",
    "\n",
    "FROM ubuntu:16.04\n",
    "\n",
    "RUN mkdir /code\n",
    "WORKDIR /code\n",
    "ADD . /code/\n",
    "ADD etc /etc\n",
    "\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "        openmpi-bin \\\n",
    "        python3-pip \\ \n",
    "        python3-dev \\ \n",
    "        python3-setuptools \\\n",
    "        supervisor \\\n",
    "        nginx && \\\n",
    "    ln -s /usr/bin/python3 python && \\\n",
    "    pip3 install --upgrade pip && \\\n",
    "    rm /etc/nginx/sites-enabled/default && \\\n",
    "    cp /code/nginx/app /etc/nginx/sites-available/ && \\\n",
    "    ln -s /etc/nginx/sites-available/app /etc/nginx/sites-enabled/ && \\\n",
    "    pip install -r /code/requirements.txt\n",
    "\n",
    "EXPOSE 88\n",
    "CMD [\"supervisord\", \"-c\", \"/etc/supervisord.conf\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test locally\n",
    "```bash\n",
    "curl --request POST --header \"Content-Type: application/json\" --data '{\"url\": \"/url/to/image\"}' http://0.0.0.0:88/score\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to Azure Kubernetes Service\n",
    "\n",
    "1. Push the docker image to ACR\n",
    "```bash\n",
    "az acr login -n {my_acr}\n",
    "docker image tag {my_image} {my_acr}.azurecr.io/{my_image}\n",
    "docker push {my_acr}.azurecr.io/{my_image}\n",
    "# test the image\n",
    "docker run --rm -p 88:88 {my_acr}.azurecr.io/{my_image}\n",
    "# run the curl command above to test the web service\n",
    "```\n",
    "2. Create AKS in the portal or using Azure Cli\n",
    "  - To connect to AKS, make sure you have the latest Azure Cli. On DSVM, you may need to do the following - \n",
    "```bash\n",
    "# dollar sign crashes Jupyter notebook, when you run the following command, replace with real dollar sign\n",
    "pip uninstall azure-cli\n",
    "AZ_REPO=dollar_sign(lsb_release -cs)\n",
    "echo \"deb [arch=amd64] https://packages.microsoft.com/repos/azure-cli/ dollar_sign{AZ_REPO} main\" | sudo tee /etc/apt/sources.list.d/azure-cli.list\n",
    "curl -L https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -\n",
    "sudo apt-get install apt-transport-https\n",
    "sudo apt-get update && sudo apt-get install azure-cli\n",
    "whereis az\n",
    "# if az is still the old version\n",
    "sudo cp /usr/bin/az /opt/az/bin/az\n",
    "sudo mv /opt/az/bin/az.bat /tmp\n",
    "ln -s /usr/bin/az /anaconda/envs/py35/bin/az\n",
    "```\n",
    "3. Connect Kubenetes Client\n",
    "```bash\n",
    "az aks get-credentials --resource-group {my_rg} --name {my_aks}\n",
    "# install kubenetes client\n",
    "sudo chmod 777 /usr/local/bin\n",
    "az aks install-cli\n",
    "kubectl cluster-info # should return AKS info\n",
    "kubectl get nodes # should return AKS nodes\n",
    "kubectl proxy # on DSVM, it says 8001 is already in use, on Windows, it only returns API interface not dashboard\n",
    "# bring up Kubenetes dashboard, this works on Windows, doesn't work on DSVM\n",
    "az aks browse --resource-group {my_rg} --name {my_aks}\n",
    "```\n",
    "4. Grant AKS access to ACR\n",
    "```bash\n",
    "# get the service principal that AKS uses to manage cluster resources\n",
    "az aks show --resource-group {my_rg} --name {my_aks} --query \"servicePrincipalProfile.clientId\" --output tsv\n",
    "# grant AKS service principal read access to ACR\n",
    "az acr show --name {my_acr} --resource-group {my_rg} --query \"id\" --output tsv\n",
    "az role assignment create --assignee {service_principal_client_id} --role Reader --scope {acr_id} \n",
    "```\n",
    "5. Deploy the web service (in docker image) to AKS\n",
    "  - Go to the Kubenetes dashboard, +Create a deployment, give it a name, the ACR image tag, add an external service which maps a port to port 88 on the container. Deploy. \n",
    "  - Run ```kubectl get pods```, ```kubectl get svc``` to see the progress and the service endpoint\n",
    "  - Test against the external IP of the service endpoint\n",
    "  - To test a simple app, run ```kubectl run kubernetes-bootcamp --image=gcr.io/google-samples/kubernetes-bootcamp:v1 --port=8080```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
